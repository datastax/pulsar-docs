= Production Cluster Sizing

This document summarizes DataStax's recommendations for the sizing and optimization of Apache Pulsars cluster on Linux in a production environment, whether that environment is on virtual machines or bare metal.

Of course, the sizing of a cluster depends on factors like use case and expected load, so this document is not intended to be a one-size-fits-all guide. Rather, we'd like to demonstrate how we consider and solve the problems inherent in sizing Pulsar clusters, and assist you on your journey to unlocking the scaling power of Pulsar.

This page summarizes the requirements, assumptions, definitions, and methodologies that inform our cluster sizing recommendations.
For deployment-specific recommendations, see the following pages:

* xref:production-cluster-bare-metal.adoc[]
* xref:production-cluster-helm.adoc[]
* xref:production-cluster-multiregion.adoc[]
* xref:production-cluster-sandbox.adoc[]

== Definitions

Pulsar cluster sizing is a complex topic, and it's important to define some terms before we dive in.

[#pulsar-server-instance]
* _Pulsar server instance:_ The Pulsar server process of a certain component type that delivers the desired Pulsar functionality.
** In VM-based deployments, the Pulsar server instance runs directly on a server host machine.
** In K8s-based deployments, the Pulsar server instance runs inside a Kubernetes pod.

[#vm-node-count]
* _VM node count:_ A VM node is the actual host machine.
** In a K8s-based deployment, 1 VM node equals 1 K8s node, and a K8s node may contain multiple pods with different server components.

[#pulsar-node-count]
* _Pulsar node count:_ A Pulsar node is a pricing calculation unit. One VM node may represent multiple Pulsar nodes. For example:
** One 8-CPU VM node is counted as 1 Pulsar node.
** One 16-CPU VM node is counted as 2 Pulsar nodes.

[#required-components]
== Required server components

The minimum deployment of a Pulsar cluster MUST have the following server components.

* Dedicated zookeeper nodes (VM deployment) or pods (K8s deployment) +
[NOTE]
====
Non-Zookeeper metadata stores are NOT supported in Pulsar server versions before 2.10.
====
* Dedicated broker nodes/pods
* Dedicated Bookkeeper nodes/pods
* Dedicated Autorecovery nodes/pods are needed on their own host machines. +
AutoRecovery detects bookkeeper node/pod failure and automatically recovers any under-replicated bookkeeper ledger data. +
For a production environment, is it NOT recommended to deploy autorecovery processes on each bookkeeper node/pod.
* Dedicated functions worker nodes/pods
If the environment uses Pulsar functions or Pulsar I/O, Pulsar function workers need to be deployed. +
For production deployment, it is NOT recommended to deploy functions workers as part of the brokers.
* Dedicated Pulsar proxy nodes/pods +
Proxy pods are more relevant in K8s-based deployments than VM-based deployments.

The diagram below illustrates a minimum Pulsar cluster deployment with a message replication factor of 3.

=== Recommended server components

The DataStax Luna Streaming Helm chart deployment includes optional but highly recommended server components for better Pulsar cluster metrics monitoring and operation visibility.
These components are NOT included in the VM-based deployment.
If your enterprise has its own monitoring and metrics dashboarding system, these components are NOT required.

* Pulsar AdminConsole nodes/pods
* Pulsar Heartbeat nodes/pods
* Prometheus/Grafana/Alert manager stack nodes/pods

[#assumptions]
== Assumptions

The methodology in this guide relies on the assumption that the ratio of the broker instance count to the bookkeeper instance count is static.
For this example, we're using 1-to-5 as the static broker-to-bookkeeper ratio.

The broker instance count calculation based on this assumption MUST be adjusted if it violates minimum Pulsar cluster topology requirements. These requirements are:
* At least one broker instance per physical rack or availability zone
* Broker instances must be evenly distributed across all physical racks or availability zones

Our sizing methodology is mainly driven by Bookkeeper ledger disk storage analysis (requirement vs capacity).
It is therefore relatively accurate in determining the sizing needs for Bookkeepers.
Sizing needs for brokers, however, are more complex. Broker workload is CPU and/or memory driven and it is hard to quantify CPU requirement vs. capacity from simple calculations.

Dedicated functions workers (when relevant) pose an even greater challenge, because the workload characteristics of deployed Pulsar functions can be very random, as well as being CPU intensive, memory intensive, disk I/O intensive, or some combination thereof. For these reasons, if we want to get a more accurate sizing calculation for a Pulsar cluster, we have to turn to a more advanced, performance testing and analysis-based approach.

We use the methodology as described in this document as a starting point, and then tune accordingly based on performance results.

[#methodology]
== Methodology

. Determine the Pulsar server instance counts for all required server component types.
.. Multiply replication factor by average message payload size by average message throughput.
+
[source,plain]
----
Total message size size  (raw) = 
3 *    // replication factor: 3
1k *   // average message payload size: 11k bytes
100k * // average message throughput: 100k message/sec
(24 * 3600)    // TTL and retention period: 1 day
  = 25,920,000 MB
  ≅ 25 TB
----
.. We now know our cluster needs 25 TB of storage for Bookkeeper ledger data, so we can calculate the number of Bookkeeper nodes with the ledger disk capacity of 4TB and an 85% effective utilization ratio.
+
[source,plain]
----
Bookkeeper count(raw)=ceiling(25/(4 * 0.85)) = 8
----

With our <<assumptions,assumption>> of a 1-to-5 broker-to-bookkeeper ratio, we calculate the number of broker nodes.
+
[source,plain]
----
Broker count(raw)=ceiling(8/5) = 2
----


== Sizing analysis and calculation example

Assume a Pulsar cluster has the following workload, topology, and VM hardware characteristics:

.Workload input characteristics
[cols=2*,options=header]
|===
|*Workload input*
|*Value*

|Average message throughput
|100 K messages/second

|Average message payload size
|1 K bytes

|Message compression
|None

|Message replication factorfootnote:[This should match the number of the availability zones (see Pulsar topology information below)]
|3

|Message retention and TTL periodfootnote:[Unacknowledged messages will expire after 1 day. Acknowledged messages will continue stay in the system up to 1 day]
|1 day

|===

.Topology characteristics
[cols=2*,options=header]
|===
|*Topology requirements*
|*Value*

|Availability Zones (AZs)footnote:[Pulsar server instances (of the same component type) should be evenly distributed across 3 AZs as much as possible, with minimum 1 Pulsar server instance per component type.]
|3

|Required Pulsar server components
|Zookeepers, Bookkeepers, Brokers, Standalone autorecovery, Pulsar Proxy

|Broker to bookkeeper ratio
|1-to-5

|===

.VM hardware characteristics
[cols=2*,options=header]
|===
|*VM hardware specification*
|*Value*

|VM Hardware specification
|The disk space for bookkeeper is 4TB per bookkeeper server instancefootnote:[Effective bookkeeper ledger disk utilization percentage is 85%]

|===

=== Calculations

We apply our <<methodology>> to these characteristics to size a production cluster. +

. Determine the Pulsar server instance counts for all required server component types.
.. Multiply replication factor by average message payload size by average message throughput.
+
[source,plain]
----
Total message size size  (raw) = 
3 *    // replication factor: 3
1k *   // average message payload size: 11k bytes
100k * // average message throughput: 100k message/sec
(24 * 3600)    // TTL and retention period: 1 day
  = 25,920,000 MB
  ≅ 25 TB
----
.. We now know our cluster needs 25 TB of storage for Bookkeeper ledger data, so we can calculate the number of Bookkeeper nodes with the ledger disk capacity of 4TB and an 85% effective utilization ratio.
+
[source,plain]
----
Bookkeeper count(raw)=ceiling(25/(4 * 0.85)) = 8
----

.. With our <<assumptions,assumption>> of a 1-to-5 broker-to-bookkeeper ratio, we calculate the number of broker nodes.
+
[source,plain]
----
Broker count(raw)=ceiling(8/5) = 2
----

.. Now we know the Pulsar server instance counts after considering Pulsar topology requirements.

.Pulsar cluster component count
[cols=5*, options=header]
|===
|Pulsar server component
|Total VM count (raw)
|Total VM count (adjusted)
|Per-AZ count distribution (adjusted)
|Notes

|Zookeeper
|
|5
|2/2/1
.5+a|* 3 AZs +
* At least 1 Pulsar server instance per AZ +
* Even distribution of Pulsar server instances across AZs

|Bookkeeper
|8
|9
|3/3/3

|Broker
|2
|3
|1/1/1

|Pulsar proxy
|
|3
|1/1/1

|===

=== Determine VM node count

Now that we know the Pulsar server instance count, we can determine the VM and K8s node counts.

Recall that for VM clusters, the VM node count is 1 VM = 1 node, while for clusters on K8s, the VM node count is 1 VM = 1 K8s node.

.Pulsar cluster CPU and memory requirements
[cols=6*, options=header]
|===
|Pulsar server component
|Pulsar server instance count
|CPU core per server instance
|Memory in GB per server insance
|Total CPU core
|Total memory in GB

|Zookeeper
|5
|1
|4
|5
|20

|Bookkeeper
|9
|4
|12
|36
|108

|Broker
|3
|8
|24
|24
|72

|Standalone autorecovery
|3
|1
|2
|3
|6

|Pulsar proxy
|3
|1
|2
|3
|6

4+|Total CPU and memory resource requirements
|71
|212

|===

=== Determine K8s VM node count

One extra step is required for the K8s-based deployment. +
Since each Pulsar server instance is running in a K8s pod and one K8s node can have multiple K8s pods, we need to first get the total resource requirement (CPU and memory) and then derive the needed VM node count. +
From the Pulsar cluster CPU and memory requirements table above, the total CPU and memory requirement is 71 CPU cores and 212 GB memory.
The required K8s node count calculation is as below, assuming 20% extra capacity for K8s system pods and/or the Pulsar server instance pods of optional Pulsar server component types.
[source,plain]
----
# Node count
(by Total CPU core requirement)
ceiling(71 * (1 + 20%) / 8) = 11
----
[source,plain]
----
# Node Count
(by Total Memory in GB requirement)
ceiling(212 * (1 + 20%) / 32) = 8
----
[source,plain]
----
# Final node count
Max(11, 8) = 11
----

For a typical K8s Pulsar deployment, the above Pulsar server instances (pods) can be allocated from one node pool (or node group).
Within the nodepool, each VM node has the same hardware specifications.
For CPU and memory, we recommend the following specications for each K8s VM node:
* CPU: 8-core
* Memory: 32 GB

=== Determine Pulsar node count (Pricing)

The Pulsar node count for pricing is determined with the same methodology as the K8s VM node count.



